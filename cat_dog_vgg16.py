# -*- coding: utf-8 -*-
"""cat_dog_vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pdU1-pCteHNrTfZhsGJeeP4qtrtjKmkr

<h1 align=center><font size = 6>Classify Cat and Dog Images with VGG-16</font></h1>

<img src="https://d.newsweek.com/en/full/1809693/cat-dog.jpg?w=1600&h=900&q=88&f=772f894f001bafc6c5094cc33d71bc19" width=1000 height=450 alt="https://d.newsweek.com/"/>

<small>Picture Source: <a href="https://www.newsweek.com/cat-becomes-dog-copying-behavior-adorable-video-1595916">Newsweek</a></small>

<br>

<h2>Objective</h2>

<p>Project was conducted as part of the <b>Computer Vision</b> lecture with the code <b>02010012</b>, which is a course offered by the Computer Engineering faculty. Computer Vision is an interdisciplinary field of study that focuses on enabling computers to interpret and understand visual information from the world around us. It involves the use of various techniques, including image processing, pattern recognition, and machine learning, to analyze and interpret digital images and videos. This project specifically focused on the use of <i>deep learning</i>, which is a subfield of <i>machine learning</i> that involves the use of <i>neural networks</i> to model complex relationships between input and output data. <i>The VGG-16</i> model is a <i>deep neural network architecture</i> that has proven to be highly effective in image classification tasks, as demonstrated by its success in the <i>ImageNet Large Scale Visual Recognition Challenge</i>.</p>

<br>

<p>By applying this knowledge and utilizing the <i>VGG-16</i> model, you were able to develop a high-performing image <i>classification</i> model for cats and dogs. This project showcases the practical application of computer vision and deep learning techniques in solving real-world problems, and highlights the importance of these techniques in the field of computer engineering.</p>

<br>

<p>The objective of this project is to develop a deep learning model using the VGG16 architecture to classify images of cats and dogs with high accuracy. The model will be trained on a dataset of labeled images and evaluated. The ultimate goal is to create a model that can accurately distinguish between images of cats and dogs in real-world scenarios.</p>

<br>

<h2>Context</h2>

<p>The dataset consists of 1,425 digital images of domestic animals, specifically 713 images of dogs and 712 images of cats. These images were collected for the purpose of training a deep learning model to classify images of cats and dogs with high accuracy. All images were obtained from various online sources and manually labeled by experts to ensure accuracy of the dataset. The images vary in size and resolution, and were preprocessed to remove any artifacts or unwanted information.</p>

<br><a href=''></a>

<h2>Table of Contents</h2>

<div class="alert alert-block alert-info" style="margin-top: 20px">
  <ul>
    <li><a href="https://#appropriate_environment">Create the Appropriate Environment</a></li>
    <li><a href="https://#libraries">Import Libraries and Packages </a></li>
    <li><a href="https://#data_preparation">Dataset Preparation</a></li>
    <li><a href="https://#compile_fit">Compile VGG-16 Model</a></li>
    <li><a href="https://#train_model">Train the VGG16 Model</a></li>
    <li><a href="https://#evaluate_model">Evaluate the VGG16 Model</a></li>
    <li><a href="https://#upload_pred">Upload and Predict Your Picture!</a></li>
  </ul>

  <br>

  <p>Estimated Time Needed: <strong>60 min</strong></p>

</div>

<br>

<h2 align=center id="appropriate_environment">Create the Appropriate Environment</h2>

<p>After downloading the dataset, we can create the appropriate environment for the data and we can unzip the file.</p>
"""

!mkdir cat_dog_classification

# Commented out IPython magic to ensure Python compatibility.
# %cd cat_dog_classification

!unzip -q /content/drive-download-20230504T091834Z-001.zip

!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

"""<p>You may want to remove zip file which contains our dataset.</p>"""

# !rm -rf /content/drive-download-20230504T091834Z-001.zip

"""<br>

<h2 align=center id="libraries">Import Libraries and Packages</h2>

<p>Before we proceed, let's import the libraries and packages that we will need to complete the rest of this lab.</p>
"""

import matplotlib.pyplot as plt
import numpy as np

import datetime

import os

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import TensorBoard, CSVLogger, ModelCheckpoint

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, GlobalAveragePooling2D
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.utils import load_img, img_to_array

from sklearn.metrics import confusion_matrix, classification_report

import warnings
warnings.filterwarnings("ignore")

tf.__version__

"""<br>

<h2 align=center id="data_preparation">Dataset Preparation</h2>

<br>
<h3>Define Parameters</h3>
"""

#@markdown ---
#@markdown ### Enter number of classes:
num_classes = 1 #@param {type:"integer"}

image_resize = (224, 224)

#@markdown

#@markdown ### Enter number of epochs:
num_epochs = 8 #@param {type:"integer"}

#@markdown

#@markdown ### Enter batch sizes:
batch_size_training = 8 #@param {type:"integer"}
batch_size_validation = 4 #@param {type:"integer"}
batch_size_test = 2 #@param {type:"integer"}

#@markdown 

#@markdown ### Enter directory:
directory = "/content/cat_dog_classification" #@param {type:"string"}
#@markdown ---

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

"""<p>We are going to separate our dataset as <i>1139</i> files for training and <i>284</i> files for validation (80% - 20%).</p>

<br>
<h3>Prepare Train Generator</h3>
"""

train_generator = datagen.flow_from_directory(
    directory,
    target_size=image_resize,
    batch_size=8,
    class_mode='binary',
    subset='training'
)

print('Class indices:', train_generator.class_indices)
print('Number of train samples:', train_generator.samples)
print('First and last 5 filenames:', train_generator.filenames[0:5], train_generator.filenames[-5:])
# print('Train classes: ', train_generator.classes)

labels = list(train_generator.class_indices.keys())
freqs = np.mean(train_generator.labels, axis=0)

fig, ax = plt.subplots(figsize=(20, 5))
ax.bar(labels, freqs, color=['green', 'red'])
ax.set_xlabel('Class Labels')
ax.set_ylabel('Frequency')
ax.set_title('Distribution of Class Labels in Training Set')
plt.xticks(rotation=90)
plt.show()

"""<p>A balanced dataset is a dataset in which all classes or categories have approximately the same number of samples. This means that no class is overrepresented or underrepresented in the dataset. In other words, a balanced dataset has a uniform distribution of samples across all classes.</p>

<p>Having a balanced dataset is important for training machine learning models because it ensures that the model is exposed to an equal number of examples from all classes.</p>
"""

labels = train_generator.classes
unique_labels, label_counts = np.unique(labels, return_counts=True)

print("Number of unique labels:", len(unique_labels))
for label, count in zip(unique_labels, label_counts):
    print("Label:", label, "- Count:", count)

"""<br>
<h4>Dive Into Batches</h4>

<p>The batch size refers to the number of samples that will be processed by the model in each training iteration. For example, if the batch size is set to 32, then the model will process 32 samples at a time during each iteration. Larger batch sizes can lead to faster training times, but can also require more memory and may be less accurate. Smaller batch sizes can be slower, but may result in better generalization and less overfitting.</p>
"""

first_batch = train_generator.next()
first_batch[0]

first_batch[1]

fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))

ind = 0
for ax1 in axs:
    for ax2 in ax1: 
        image_data = first_batch[0][ind]
        ax2.imshow(image_data)
        ind += 1

fig.suptitle('First Batch of Train Images') 
plt.show()

"""<br>
<h3>Prepare Validation Generator</h3>
"""

validation_generator = datagen.flow_from_directory(
    directory,
    target_size=(224, 224),
    batch_size=4,
    class_mode='binary',
    subset='validation'
)

print('Class indices:', validation_generator.class_indices)
print('Number of validation samples:', validation_generator.samples)
print('First and last 5 filenames:', validation_generator.filenames[0:5], validation_generator.filenames[-5:])
# print('Validation classes: ', validation_generator.classes)

"""<br>

<p>The "Distribution of Class Labels in Training Set" plot shows the distribution of samples across the different classes or categories in the <i>training set</i>. The <i>x-axis</i> represents the different classes, and the y-axis represents the frequency or number of <i>samples</i> in each <i>class</i>. Each <i>bar</i> in the plot represents a class, and its height corresponds to the number of samples in that class.</p>

<br>

<p>By <i>examining</i> this <i>plot</i>, you can get a sense of how <i>balanced</i> or <i>imbalanced</i> your <i>dataset</i> is. If the height of the bars is roughly the same for all classes, then your <i>dataset</i> is considered to be balanced. If some bars are much taller than others, then your dataset is considered to be <i>imbalanced</i>, with some <i>classes</i> having more samples than others.</p>

<br>

<p>This plot is helpful for understanding the underlying distribution of your dataset and identifying any potential <i>imbalances</i> that may affect your model's performance. <b>If your <i>dataset</i> is <i>imbalanced</i>, you may need to consider using techniques such as <i>oversampling</i> or <i>undersampling</i> to create a more balanced dataset</b>.</p>
"""

labels = list(validation_generator.class_indices.keys())
freqs = np.mean(validation_generator.labels, axis=0)

fig, ax = plt.subplots(figsize=(20, 5))
ax.bar(labels, freqs, color=['blue', 'orange'])
ax.set_xlabel('Class Labels')
ax.set_ylabel('Frequency')
ax.set_title('Distribution of Class Labels in Training Set')
plt.xticks(rotation=90)
plt.show()

labels = validation_generator.classes
unique_labels, label_counts = np.unique(labels, return_counts=True)

print("Number of unique labels:", len(unique_labels))
for label, count in zip(unique_labels, label_counts):
    print("Label:", label, "- Count:", count)

"""<p>Having a <i>balanced dataset</i> is important for training <i>machine learning models</i> because it ensures that the model is exposed to an equal number of examples from all classes. This is particularly important in <i>classification problems</i>, where the goal is to <i>predict</i> the correct <i>class label</i> for a given input sample. If a <i>dataset</i> is imbalanced, where some classes have much fewer examples than others, the <i>model</i> may learn to be <i>biased</i> towards the <i>majority class</i> and perform poorly on the <i>minority classes</i>.</p>

<p><i>Balancing</i> a <i>dataset</i> can be achieved through various techniques, such as <b><i>oversampling the minority classes</i>, <i>undersampling the majority classes</i>, or using a <i>combination</i> of both</b>. These techniques aim to <i>adjust</i> the number of samples in each class to create a more <i>balanced dataset</i>.</p>

<br>
<h4>Dive Into Batches</h4>

<p>The <i>batch</i> size determines the number of <i>samples</i> processed in each <i>iteration</i>.</p>
"""

first_batch = validation_generator.next()
first_batch[0]

first_batch[1]

fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 10))

ind = 0
for ax1 in axs: 
    image_data = first_batch[0][ind]
    ax1.imshow(image_data)
    ind += 1

fig.suptitle('First Batch of Validation Images') 
plt.show()

"""<br>

<h2 align=center id="compile_fit">Compile VGG-16 Model</h2>

<p><i>VGG-16</i> is a <i>convolution neural net (CNN)</i> architecture which was used to win <i>ILSVR (Imagenet)</i> competition in 2014. It is considered to be one of the excellent <i>vision model architecture</i> till date. In this section, we will start building our model. We will use the <i>Sequential model class</i> from <i>Keras</i>.</p></p>

<br>
<h3>Build VGG-16 Model</h3>
"""

model_vgg16 = Sequential()

"""<p>Then, we will define our output layer as a <b>Dense</b> layer.</p>"""

model_vgg16.add(VGG16(include_top=False, pooling="avg", weights="imagenet"))
model_vgg16.add(Dense(64, activation='softmax', name = 'dense'))
model_vgg16.add(Dense(num_classes, activation="sigmoid", name = 'output'))

model_vgg16.layers[0].trainable = False

"""<p>You can access the model's layers using the <i>layers</i> attribute of our model object.</p>"""

model_vgg16.layers

"""<p>And now using the <i>summary</i> attribute of the model.</p>"""

model_vgg16.summary()

plot_model(model_vgg16, to_file='model_vgg16.png', show_shapes=True, show_layer_names=True)

"""<br>
<h3>Compile the Model</h3>

<p>Next, we compile our model using the <b>adam</b> optimizer.</p>
"""

model_vgg16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""<br>

<h2 align=center id="train_model">Train the VGG16 Model</h2>

<br>
<h3>Define Callback</h3>

<a name="4-1-1"></a>
#### [TensorBoard](https://www.tensorflow.org/tensorboard?hl=tr)

TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more. 

<br>

<a name="4-1-2"></a>
#### [CSVLogger](https://keras.io/api/callbacks/csv_logger/)

Callback that streams epoch results to a CSV file.

<br>

<a name="4-1-3"></a>
#### [ModelCheckpoint](https://keras.io/api/callbacks/model_checkpoint/)

ModelCheckpoint callback is used in conjunction with training using <code>model.fit()</code> to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.
"""

get_ipython().system('rm -rf logs')

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = TensorBoard(logdir)

csv_file = 'training.csv'

callbacks_list = [tensorboard_callback, CSVLogger(csv_file), ModelCheckpoint('/content/' + 'best_model.h5', verbose=1)]

"""<br>
<h3>Fit the Model</h3>
"""

import time
start = time.time()

history = model_vgg16.fit(train_generator, 
                    epochs=num_epochs,
                    validation_data=validation_generator,
                    callbacks=[callbacks_list])

end = time.time()

elapsed_time = end - start

print(f"Elapsed Time:{elapsed_time}s")

"""<br>
<h3>Save the Model</h3>
"""

model_vgg16.save('/content/')

"""<br>

<h2 align=center id="evaluate_model">Evaluate the VGG16 Model</h2>

<p>Evaluating a CNN model is a crucial step in the development of a deep learning project. It helps in understanding how well the model performs on unseen data and provides insights into whether the model is overfitting or underfitting. Evaluation of the CNN model is important for the following reasons:</p>

<br>

<ol>
  <li><b>Performance measurement:</b> Evaluating a model helps in measuring its performance on the test data. This gives an idea of how well the model has learned to generalize to new data.</li>

  <li><b>Model selection:</b> Evaluation of different models can help in selecting the best model among them. It is essential to choose the model with the best performance metrics to deploy it in a production environment.</li>

  <li><b>Hyperparameter tuning:</b> Evaluating a model can also help in fine-tuning the hyperparameters of the model. By comparing the performance of models with different hyperparameters, we can identify the optimal hyperparameters that produce the best performance.</li>

  <li><b>Debugging:</b> Evaluation helps in identifying and diagnosing issues in the model. It can help in determining whether the model is overfitting or underfitting, which can be addressed by adjusting the architecture or hyperparameters.</li>
</ol>

<br>
<h3>Run TensorBoard</h3>
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

get_ipython().run_line_magic('tensorboard', '--logdir logs')

"""<br>

<h2 align=center id="upload_pred">Upload and Predict Your Picture!</h2>

<br>
<h3>Load the Model</h3>
"""

# from tensorflow.keras.models import load_model
# model_vgg16 = load_model('/content/best_model.h5')

"""<p>You can upload any image and have the model predict whether it's a dog or a cat.</p>
<ul>
  <li>Find an image of a dog or cat.</li>
  <li>Run the following code cell.  It will ask you to upload an image.</li>
  <li>The model will print "is a dog" or "is a cat" depending on the model's prediction.</li>
<ul>
"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
 
  path = '/content/' + fn
  img = load_img(path, target_size=image_resize)
  x = img_to_array(img)
  x = np.expand_dims(x, axis=0)

  image_tensor = np.vstack([x])
  classes = model_vgg16.predict(image_tensor)

  print(classes)
  print(classes[0])
  if classes[0] > 0.5:
    print(fn + " is a dog")
  else:
    print(fn + " is a cat")

from google.colab import files
files.download('/content/variables/variables.data-00000-of-00001')
files.download('/content/variables/variables.index')
files.download('/content/best_model.h5')
files.download('/content/fingerprint.pb')
files.download('/content/keras_metadata.pb')
files.download('/content/saved_model.pb')
files.download('/content/training.csv')

"""<h1>Contact Me</h1>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li><a href="https://twitter.com/Doguilmak">Twitter</a></li>
  <li><a href="https://github.com/doguilmak">GitHub</a></li>
  <li>doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")